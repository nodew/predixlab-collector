# ä»£ç æœ€ä½³å®è·µæŒ‡å— - QStock Collector

## ğŸ“š ç›®å½•
1. [ç¼–ç è§„èŒƒ](#ç¼–ç è§„èŒƒ)
2. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
3. [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
4. [æµ‹è¯•ç­–ç•¥](#æµ‹è¯•ç­–ç•¥)
5. [æ–‡æ¡£è§„èŒƒ](#æ–‡æ¡£è§„èŒƒ)
6. [Git æäº¤è§„èŒƒ](#git-æäº¤è§„èŒƒ)

---

## ğŸ¯ ç¼–ç è§„èŒƒ

### 1. ç±»å‹æç¤º

**âœ… æ¨èåšæ³•ï¼š**
```python
from typing import Optional, List, Dict, Any
from pathlib import Path

def process_data(
    file_path: Path,
    symbols: List[str],
    config: Optional[Dict[str, Any]] = None
) -> bool:
    """å¤„ç†æ•°æ®æ–‡ä»¶"""
    pass
```

**âŒ é¿å…ï¼š**
```python
def process_data(file_path, symbols, config=None):
    """å¤„ç†æ•°æ®æ–‡ä»¶"""
    pass
```

### 2. æ–‡æ¡£å­—ç¬¦ä¸²

**âœ… æ¨èåšæ³•ï¼ˆGoogle é£æ ¼ï¼‰ï¼š**
```python
def calculate_returns(prices: pd.Series, period: int = 1) -> pd.Series:
    """è®¡ç®—æ”¶ç›Šç‡åºåˆ—ã€‚

    Args:
        prices: ä»·æ ¼åºåˆ—
        period: è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ä¸º 1

    Returns:
        æ”¶ç›Šç‡åºåˆ—

    Raises:
        ValueError: å½“ä»·æ ¼åºåˆ—ä¸ºç©ºæ—¶

    Examples:
        >>> prices = pd.Series([100, 105, 103])
        >>> returns = calculate_returns(prices)
        >>> print(returns)
    """
    if prices.empty:
        raise ValueError("ä»·æ ¼åºåˆ—ä¸èƒ½ä¸ºç©º")
    
    return prices.pct_change(period)
```

### 3. å¸¸é‡å‘½å

**âœ… æ¨èåšæ³•ï¼š**
```python
# å¸¸é‡ä½¿ç”¨å¤§å†™å­—æ¯å’Œä¸‹åˆ’çº¿
DEFAULT_START_DATE = "2015-01-01"
MAX_RETRY_ATTEMPTS = 3
API_TIMEOUT_SECONDS = 30

# é…ç½®ç±»å¸¸é‡
class Config:
    DATABASE_URL = "mongodb://localhost:27017"
    MAX_WORKERS = 8
```

**âŒ é¿å…ï¼š**
```python
default_start_date = "2015-01-01"  # åº”è¯¥ç”¨å¤§å†™
MaxRetryAttempts = 3  # ä¸è¦ç”¨é©¼å³°å‘½åå¸¸é‡
```

### 4. å‡½æ•°é•¿åº¦

**åŸåˆ™ï¼š** ä¸€ä¸ªå‡½æ•°åº”è¯¥åªåšä¸€ä»¶äº‹ï¼Œç†æƒ³é•¿åº¦ < 50 è¡Œ

**âœ… æ¨èåšæ³•ï¼š**
```python
def update_stock_data(symbol: str) -> bool:
    """æ›´æ–°è‚¡ç¥¨æ•°æ®"""
    data = fetch_data(symbol)
    if not validate_data(data):
        return False
    
    normalized = normalize_data(data)
    return save_data(normalized, symbol)

def fetch_data(symbol: str) -> pd.DataFrame:
    """è·å–æ•°æ®"""
    # ä¸“æ³¨äºæ•°æ®è·å–
    pass

def validate_data(data: pd.DataFrame) -> bool:
    """éªŒè¯æ•°æ®"""
    # ä¸“æ³¨äºæ•°æ®éªŒè¯
    pass
```

**âŒ é¿å…ï¼š**
```python
def update_stock_data(symbol: str) -> bool:
    """æ›´æ–°è‚¡ç¥¨æ•°æ®"""
    # 100+ è¡Œä»£ç åšæ‰€æœ‰äº‹æƒ…
    # æ•°æ®è·å–ã€éªŒè¯ã€å¤„ç†ã€ä¿å­˜å…¨åœ¨ä¸€ä¸ªå‡½æ•°é‡Œ
    pass
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. å‘é‡åŒ–ä¼˜å…ˆ

**âœ… æ¨èåšæ³•ï¼ˆå¿« 10-100xï¼‰ï¼š**
```python
import pandas as pd
import numpy as np

# ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
df['returns'] = df['close'].pct_change()
df['is_positive'] = df['returns'] > 0

# ä½¿ç”¨ numpy çš„å‘é‡åŒ–å‡½æ•°
with np.errstate(divide='ignore', invalid='ignore'):
    result = np.log(df['price'] / df['price'].shift(1))
```

**âŒ é¿å…ï¼ˆæ…¢ï¼‰ï¼š**
```python
# é¿å…ä½¿ç”¨ apply å’Œ lambda
df['returns'] = df['close'].apply(lambda x: ...)

# é¿å…ä½¿ç”¨å¾ªç¯
for i in range(len(df)):
    df.loc[i, 'returns'] = calculate_return(df.loc[i, 'close'])
```

### 2. å†…å­˜ç®¡ç†

**âœ… æ¨èåšæ³•ï¼š**
```python
# ä½¿ç”¨ copy() æ˜ç¡®è¡¨ç¤ºéœ€è¦å‰¯æœ¬
df_filtered = df[df['volume'] > 0].copy()
df_filtered['new_column'] = calculate_value(df_filtered)

# åŠæ—¶åˆ é™¤ä¸éœ€è¦çš„å¤§å¯¹è±¡
large_df = load_large_data()
process_data(large_df)
del large_df  # é‡Šæ”¾å†…å­˜

# ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ–‡ä»¶
def read_large_file(file_path: Path):
    with open(file_path) as f:
        for line in f:
            yield process_line(line)
```

**âŒ é¿å…ï¼š**
```python
# ä¸å¿…è¦çš„æ•°æ®å¤åˆ¶
df_copy = df.copy()  # å¦‚æœä¸éœ€è¦ï¼Œä¸è¦å¤åˆ¶
df_copy2 = df_copy.copy()  # å¤šæ¬¡å¤åˆ¶

# åœ¨å¾ªç¯ä¸­åˆ›å»ºå¤§å¯¹è±¡
for symbol in symbols:
    full_history = load_all_data(symbol)  # å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º
```

### 3. æ‰¹å¤„ç†

**âœ… æ¨èåšæ³•ï¼š**
```python
# æ‰¹é‡å¤„ç†ä»¥å‡å°‘ I/O
BATCH_SIZE = 100

for i in range(0, len(symbols), BATCH_SIZE):
    batch = symbols[i:i + BATCH_SIZE]
    data = fetch_batch_data(batch)  # ä¸€æ¬¡è¯·æ±‚å¤šä¸ª
    process_batch(data)
```

**âŒ é¿å…ï¼š**
```python
# é€ä¸ªå¤„ç†å¯¼è‡´é¢‘ç¹ I/O
for symbol in symbols:
    data = fetch_data(symbol)  # æ¯æ¬¡ä¸€ä¸ªè¯·æ±‚
    process_data(data)
```

---

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†

### 1. å…·ä½“çš„å¼‚å¸¸ç±»å‹

**âœ… æ¨èåšæ³•ï¼š**
```python
from typing import Optional

def read_config(path: Path) -> Optional[Dict]:
    """è¯»å–é…ç½®æ–‡ä»¶"""
    try:
        with open(path) as f:
            return json.load(f)
    except FileNotFoundError:
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return None
    except json.JSONDecodeError as e:
        logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return None
    except PermissionError:
        logger.error(f"æ²¡æœ‰æƒé™è¯»å–é…ç½®æ–‡ä»¶: {path}")
        return None
```

**âŒ é¿å…ï¼š**
```python
def read_config(path: Path):
    try:
        with open(path) as f:
            return json.load(f)
    except Exception as e:  # å¤ªå®½æ³›
        logger.error(f"é”™è¯¯: {e}")
        return None
```

### 2. èµ„æºæ¸…ç†

**âœ… æ¨èåšæ³•ï¼š**
```python
from contextlib import contextmanager
from typing import Generator

@contextmanager
def get_db_connection() -> Generator[MongoClient, None, None]:
    """æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    client = None
    try:
        client = MongoClient(settings.mongodb_url)
        yield client
    finally:
        if client:
            client.close()

# ä½¿ç”¨
with get_db_connection() as client:
    db = client[settings.database_name]
    # ä½¿ç”¨æ•°æ®åº“
    # è‡ªåŠ¨æ¸…ç†
```

**âŒ é¿å…ï¼š**
```python
def save_to_db(data):
    client = MongoClient(settings.mongodb_url)
    db = client[settings.database_name]
    db.collection.insert_one(data)
    # å¿˜è®°å…³é—­è¿æ¥ï¼
```

### 3. è‡ªå®šä¹‰å¼‚å¸¸

**âœ… æ¨èåšæ³•ï¼š**
```python
class DataCollectionError(Exception):
    """æ•°æ®æ”¶é›†é”™è¯¯åŸºç±»"""
    pass

class DataValidationError(DataCollectionError):
    """æ•°æ®éªŒè¯é”™è¯¯"""
    pass

class APIRateLimitError(DataCollectionError):
    """API é™æµé”™è¯¯"""
    def __init__(self, retry_after: int):
        self.retry_after = retry_after
        super().__init__(f"API rate limit exceeded. Retry after {retry_after}s")

# ä½¿ç”¨
try:
    data = fetch_data(symbol)
except APIRateLimitError as e:
    logger.warning(f"é‡åˆ°é™æµï¼Œç­‰å¾… {e.retry_after} ç§’")
    time.sleep(e.retry_after)
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•ç»“æ„

```python
import pytest
from pathlib import Path
from utils import read_last_trading_date

class TestReadLastTradingDate:
    """æµ‹è¯• read_last_trading_date å‡½æ•°"""
    
    def test_normal_file(self, tmp_path):
        """æµ‹è¯•æ­£å¸¸çš„æ—¥å†æ–‡ä»¶"""
        # Arrange
        calendar_file = tmp_path / "calendar.txt"
        calendar_file.write_text("2024-01-01\n2024-01-02\n2024-01-03\n")
        
        # Act
        result = read_last_trading_date(calendar_file)
        
        # Assert
        assert result == "2024-01-02"
    
    def test_empty_file(self, tmp_path):
        """æµ‹è¯•ç©ºæ–‡ä»¶"""
        calendar_file = tmp_path / "empty.txt"
        calendar_file.write_text("")
        
        result = read_last_trading_date(calendar_file, default_date="2020-01-01")
        
        assert result == "2020-01-01"
    
    def test_missing_file(self, tmp_path):
        """æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶"""
        calendar_file = tmp_path / "missing.txt"
        
        result = read_last_trading_date(calendar_file, default_date="2020-01-01")
        
        assert result == "2020-01-01"
    
    def test_invalid_date_format(self, tmp_path):
        """æµ‹è¯•æ— æ•ˆçš„æ—¥æœŸæ ¼å¼"""
        calendar_file = tmp_path / "invalid.txt"
        calendar_file.write_text("not-a-date\n")
        
        with pytest.raises(ValueError):
            read_last_trading_date(calendar_file)
```

### 2. é›†æˆæµ‹è¯•

```python
@pytest.mark.integration
class TestDataCollection:
    """é›†æˆæµ‹è¯•ï¼šå®Œæ•´çš„æ•°æ®æ”¶é›†æµç¨‹"""
    
    @pytest.fixture
    def collector(self):
        """åˆ›å»ºæ”¶é›†å™¨å®ä¾‹"""
        return YahooCollector(
            start_date="2024-01-01",
            end_date="2024-01-31",
            interval="1d",
            limit_nums=5  # é™åˆ¶æµ‹è¯•æ•°æ®é‡
        )
    
    def test_full_collection_pipeline(self, collector, tmp_path):
        """æµ‹è¯•å®Œæ•´çš„æ”¶é›†æµç¨‹"""
        # è®¾ç½®æµ‹è¯•ç›®å½•
        collector.us_stock_data_dir = tmp_path / "stock_data"
        
        # æ‰§è¡Œæ”¶é›†
        collector.collect()
        
        # éªŒè¯ç»“æœ
        csv_files = list(collector.us_stock_data_dir.glob("*.csv"))
        assert len(csv_files) > 0
        
        # éªŒè¯æ•°æ®æ ¼å¼
        df = pd.read_csv(csv_files[0])
        required_cols = ['date', 'open', 'high', 'low', 'close', 'volume']
        assert all(col in df.columns for col in required_cols)
```

### 3. æ€§èƒ½æµ‹è¯•

```python
import pytest
import time

def test_vectorized_filter_performance():
    """æµ‹è¯•å‘é‡åŒ–è¿‡æ»¤çš„æ€§èƒ½"""
    # åˆ›å»ºå¤§æ•°æ®é›†
    n = 100000
    df = pd.DataFrame({
        'date': pd.date_range('2020-01-01', periods=n, freq='1min'),
        'close': np.random.randn(n)
    })
    
    collector = YahooCollector(interval="1d")
    
    # æµ‹é‡æ€§èƒ½
    start = time.time()
    result = collector._filter_data(df)
    duration = time.time() - start
    
    # åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆ< 1ç§’ï¼‰
    assert duration < 1.0
    assert len(result) > 0
```

---

## ğŸ“– æ–‡æ¡£è§„èŒƒ

### 1. README æ›´æ–°

æ¯æ¬¡é‡è¦åŠŸèƒ½æ·»åŠ åï¼Œæ›´æ–° READMEï¼š

```markdown
## æ–°åŠŸèƒ½ï¼šæ‰¹é‡æ•°æ®æ”¶é›†

### ä½¿ç”¨æ–¹æ³•
```python
from collectors.yahoo import YahooCollector

# åˆ›å»ºæ”¶é›†å™¨
collector = YahooCollector(
    start_date="2024-01-01",
    interval="1d",
    limit_nums=100  # é™åˆ¶å¤„ç†æ•°é‡
)

# æ‰§è¡Œæ”¶é›†
collector.collect()
```

### æ€§èƒ½ç‰¹ç‚¹
- æ”¯æŒæ‰¹é‡ä¸‹è½½ï¼Œé€Ÿåº¦æå‡ 5-10x
- è‡ªåŠ¨å¼‚å¸¸æ£€æµ‹å’Œé‡è¯•
- å†…å­˜ä¼˜åŒ–ï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®å¤„ç†
```

### 2. å˜æ›´æ—¥å¿—

ç»´æŠ¤ `CHANGELOG.md`ï¼š

```markdown
## [0.2.0] - 2025-01-XX

### Added
- æ–°å¢æ‰¹é‡æ•°æ®æ”¶é›†åŠŸèƒ½
- æ·»åŠ äº†å·¥å…·æ¨¡å— `utils.py`
- é…ç½®éªŒè¯åŠŸèƒ½

### Changed
- é‡æ„äº† `main.py`ï¼Œå‡å°‘ä»£ç é‡å¤ 60%
- ä¼˜åŒ–äº†æ•°æ®è¿‡æ»¤æ€§èƒ½ï¼ˆ10-100x æå‡ï¼‰

### Fixed
- ä¿®å¤äº†æ•°æ®åº“è¿æ¥æœªå…³é—­çš„é—®é¢˜
- ä¿®å¤äº†å¼‚å¸¸æ£€æµ‹ä¸­çš„é™¤é›¶è­¦å‘Š

### Deprecated
- `old_function()` å°†åœ¨ v0.3.0 ä¸­ç§»é™¤

### Removed
- ç§»é™¤äº†ä¸å†ä½¿ç”¨çš„ `legacy_module.py`
```

---

## ğŸ“ Git æäº¤è§„èŒƒ

### 1. æäº¤ä¿¡æ¯æ ¼å¼

```
<type>(<scope>): <subject>

<body>

<footer>
```

### 2. Type ç±»å‹

- `feat`: æ–°åŠŸèƒ½
- `fix`: ä¿®å¤ bug
- `refactor`: é‡æ„ï¼ˆä¸æ”¹å˜åŠŸèƒ½ï¼‰
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `docs`: æ–‡æ¡£æ›´æ–°
- `test`: æ·»åŠ æµ‹è¯•
- `chore`: æ„å»º/å·¥å…·é“¾æ›´æ–°

### 3. ç¤ºä¾‹

```bash
# å¥½çš„æäº¤ä¿¡æ¯
git commit -m "feat(collector): add batch download support

- Implement batch data fetching for improved performance
- Add dynamic batch size calculation based on date range
- Include retry logic for failed batches

Closes #123"

# ç®€å•çš„æäº¤
git commit -m "fix(config): add MongoDB URL validation"

# é‡æ„æäº¤
git commit -m "refactor(main): extract common job status logic

- Create _prepare_job_status helper method
- Create _finalize_job_status helper method
- Reduce code duplication by 60%"
```

**âŒ é¿å…ï¼š**
```bash
git commit -m "update"
git commit -m "fix bug"
git commit -m "æ”¹äº†ä¸€äº›ä¸œè¥¿"
```

---

## ğŸ”’ å®‰å…¨å®è·µ

### 1. æ•æ„Ÿä¿¡æ¯

**âœ… æ¨èåšæ³•ï¼š**
```python
# ä½¿ç”¨ç¯å¢ƒå˜é‡
from config import settings

connection_string = settings.mongodb_url  # ä» .env è¯»å–

# .env æ–‡ä»¶ï¼ˆä¸è¦æäº¤åˆ° Gitï¼‰
MONGODB_URL=mongodb://localhost:27017
ACS_CONNECTION_STRING=endpoint=...
```

**âŒ é¿å…ï¼š**
```python
# ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
connection_string = "mongodb://user:password@host:27017"
api_key = "sk-1234567890abcdef"  # ç»å¯¹ä¸è¦è¿™æ ·åšï¼
```

### 2. .gitignore

ç¡®ä¿åŒ…å«ï¼š
```gitignore
# ç¯å¢ƒå˜é‡
.env
.env.local

# æ•æ„Ÿæ•°æ®
*.key
*.pem
secrets/

# æ•°æ®æ–‡ä»¶
data/
*.csv
*.xlsx
```

---

## ğŸ“Š ä»£ç å®¡æŸ¥æ¸…å•

æäº¤ PR å‰æ£€æŸ¥ï¼š

- [ ] æ‰€æœ‰å‡½æ•°éƒ½æœ‰ç±»å‹æç¤º
- [ ] æ‰€æœ‰å…¬å…±å‡½æ•°éƒ½æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] æ²¡æœ‰ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
- [ ] éµå¾ª DRY åŸåˆ™ï¼ˆæ— é‡å¤ä»£ç ï¼‰
- [ ] ä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼ˆé¿å…å¾ªç¯ï¼‰
- [ ] é€‚å½“çš„é”™è¯¯å¤„ç†
- [ ] èµ„æºæ­£ç¡®æ¸…ç†ï¼ˆè¿æ¥ã€æ–‡ä»¶ç­‰ï¼‰
- [ ] æ·»åŠ äº†å¿…è¦çš„æµ‹è¯•
- [ ] æ›´æ–°äº†ç›¸å…³æ–‡æ¡£
- [ ] æäº¤ä¿¡æ¯æ¸…æ™°è§„èŒƒ

---

## ğŸ“ å­¦ä¹ èµ„æº

### Python æœ€ä½³å®è·µ
- [PEP 8 - Style Guide](https://pep8.org/)
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [Effective Python](https://effectivepython.com/)

### Pandas æ€§èƒ½
- [Pandas Performance Tips](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)
- [Modern Pandas](https://tomaugspurger.github.io/modern-1-intro.html)

### æµ‹è¯•
- [Pytest Documentation](https://docs.pytest.org/)
- [Test-Driven Development](https://testdriven.io/)

---

**æœ€åæ›´æ–°**: 2025-01-XX  
**ç»´æŠ¤è€…**: å¼€å‘å›¢é˜Ÿ
